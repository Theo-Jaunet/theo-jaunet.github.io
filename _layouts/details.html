---
layout: default
---

<aside class="sidebar">
    <header>
        <div class="about">
            <div class="cover-author-image">
                <a href="{{site.baseurl}}/"><img
                        src="{{site.baseurl}}/assets/img/{% if site.author-img %}{{site.author-img}}{% endif %}"
                        alt="{{site.author}}"></a>
            </div>
            <div class="author-name">{{site.author}}</div>
            <p>{{site.about-author}}</p>
        </div>
        <section class="contact">
            <h3 class="contact-title">Contact me</h3>
            <ul>
                {% if site.social-github %}
                <li class="github"><a href="http://github.com/{{site.social-github}}" target="_blank"><i
                        class="fa fa-github"></i></a></li>
                {% endif %}
                {% if site.social-twitter %}
                <li><a href="https://twitter.com/{{ site.social-twitter }}" target="_blank"><i class="fa fa-twitter"
                                                                                               aria-hidden="true"></i></a>
                </li>
                {% endif %}

                {% if site.social-linkedin %}
                <li class="linkedin"><a href="https://in.linkedin.com/in/{{site.social-linkedin}}" target="_blank"><i
                        class="fa fa-linkedin"></i></a></li>
                {% endif %}
                {% if site.social-email %}
                <li class="email"><a href="mailto:{{site.social-email}}"><i class="fa fa-envelope-o"></i></a></li>
                {% endif %}
            </ul>
        </section> <!-- End Section Contact -->
    </header> <!-- End Header -->

    <footer>

        <!--<div class="copyright">-->
        <!--<p>{{site.time | date: '%Y'}} &copy; {{site.author}}</p>-->
        <!--</div>-->
    </footer> <!-- End Footer -->
</aside> <!-- End Sidebar -->


<div class="content-box clearfix">
    <div>
        <div style="position:relative;margin-bottom: 25px">
            <h1 style="text-align: center">Deep Learning Interpretability with Visual Analytics: </br>
                Exploring Reasoning and Bias Exploitation</h1>
            <h4 style="text-align: center"> September 2018 - May 2022</h4>
            <div style=" position:absolute;display:inline-block;left: 50%;  bottom: -24px ; -webkit-transform: translateX(-50%);    -ms-transform: translateX(-50%);    transform: translateX(-50%); width: 9px;height: 9px; -webkit-border-radius: 100%;   border-radius: 100%;background-color: #515151;"></div>
        </div>
        <p style="text-align: center;margin-top: 35px">
            Advised by <a href="http://romain.vuillemot.net/">Romain
            Vuillemot</a> and <a href="https://perso.liris.cnrs.fr/christian.wolf/">Christian Wolf</a>, </br> and
            with  </br> <a href="https://hudelotc.github.io/">CÃ©line Hudelot</a>, <a
                href="https://www.labri.fr/perso/auber/david_auber_home_page/">David Auber</a>, <a
                href="http://shixialiu.com/">Shixia Liu</a>, <a href="http://hendrik.strobelt.com/">Hendrik Strobelt</a>,
            and <a href="https://liris.cnrs.fr/page-membre/liming-chen">Liming Chen</a>  </br> as committee members.
        </p>
        <!--        <ul>
                    <li>
                        <span style="font-weight: 600;color: #424242">Advisors:</span> <a href="http://romain.vuillemot.net/">Romain
                        Vuillemot</a> and
                        <a href="https://perso.liris.cnrs.fr/christian.wolf/">Christian Wolf</a>
                    </li>
                    <li><span style="font-weight: 600;color: #424242">Internal advisor:</span> <a
                            href="https://perso.liris.cnrs.fr/aline.parreau/index.html">Aline Parreau</a></li>
                    <li><span style="font-weight: 600;color: #424242">External advisor: </span> <a
                            href="http://hendrik.strobelt.com/"> Hendrik Strobelt</a></li>
                    <li><span style="font-weight: 600;color: #424242">Fundings:</span> 3 years by a French ministry Ph.D.
                        fellowship and supported by
                        the <a href="https://projet.liris.cnrs.fr/mi2/"> M2I project</a></li>
                    <li><span style="font-weight: 600;color: #424242">Duration: </span> september 2018 &#45;&#45; september 2021</li>
                    <li><span style="font-weight: 600;color: #424242">Affiliations: </span> <a href="https://liris.cnrs.fr">LIRIS
                        lab</a>, and <a href="https://www.insa-lyon.fr/">INSA-Lyon</a>
                    </li>

                </ul>-->

        <div style="text-align: center">
            <h2 style="text-align: center"> Abstract </h2>
            <p style="text-align: center;margin-bottom: 15px">
                In the last couple of years, Artificial Intelligence (AI) and Machine Learning have evolved, from
                research domains addressed in laboratories far from the public
                eye, to technology deployed on industrial scale widely impacting our daily lives. This trend has started
                to raise legitimate concerns, as it is also used to address
                critical problems like finance and autonomous driving, in which decisions can have a life-threatening
                impact. Since a large part of the underlying complexity of
                the decision process is learned from massive amounts of data, it remains unknown to both the builders of
                those models and to the people impacted by them how
                models take decisions. This led to the new field of eXplainable AI (XAI) and the problem of analyzing
                the behavior of trained models to shed their reasoning
                modes and the underlying biases they are subject to. This thesis we contributed to this emerging field
                with the design of visual analytics systems tailored to the
                study and improvement of interpretability of Deep Neural Networks. Our goal was to empower experts with
                tools helping them to better interpret the decisions
                of their models. We also contributed with explorable applications designed to introduce Deep Learning
                methods to non-expert audiences. Our focus was on
                the under-explored challenge of interpreting and improving models for different applications such as
                robotics, where important decisions must be taken from
                high-dimensional and low-level inputs such as images.
            </p>


            <a href="https://theo-jaunet.github.io/assets/papers/phd.pdf"><img
                    style="height: auto;border: solid #555555 1px"
                    class="page-image shad"
                    src="/assets/img/phd.jpeg"></a>
            <p> The manuscript is accessible <a
                    href="https://theo-jaunet.github.io/assets/papers/phd.pdf"> online</a>.
            </p>
        </div>

        <div style="text-align: center"> This work was conducted at <a href="https://liris.cnrs.fr">LIRIS lab</a>, and <a
                href="https://www.insa-lyon.fr/">INSA-Lyon</a>, thanks to the support of a dedicated French Ministry
            fellowship.
        </div>
    </div>


</div>