---
layout: post
title: "DRLViz"
fulltitle: "DRLViz: Understanding Decisions and Memory in Deep Reinforcement Learning"
date: 2019-08-26 13:32:20 +0300
description: "A visual analytics interface to interpret the internal memory of an agent (e.g. a robot) trained using deep reinforcement learning."
img: drlviz.png
teaser: drlviz_teaser.png
fig-caption: : Summary of the insights gained by the experts. In the trajectory ① and stream-graph of actions ② Expert #1 noticed two intervals during which the agent only turned right. After replaying those sequences, Expert #1 stated that the agent came twice in the same dead-end ③. Expert #3 observed a hidden state dimension which is blue when the agent sees the red armor before the green armor, and then remained orange until when saw the green armor ④. Expert #2 probed a dimension that is active as the agent first saw the HP, and remained active until it gathered it. Expert #1 also identified two hidden state elements that changes as the agent gathered the health pack and then kept their values until the end of the episode ⑥. Using saliency maps ⑦, Expert #2 observed that the agent ignore the soul-sphere until it gathered the 3 firsts items ⑧. Finally, Expert #3 identified clusters in the t-SNE projection which corresponds to the agent’s objectives e. g., gathering the green armor ⑨.
authors: "Theo Jaunet, Romain Vuillemot, Christian Wolf"
conf: In review for TVCG 2020
demo: https://sical.github.io/drlviz/
paper_tease: drlviz_paper.png
git: https://github.com/sical/drlviz
paper: https://arxiv.org/abs/1909.02982
test: ok
---

 
## Abstract   

We present DRLViz, a visual analytics interface to interpret the internal memory of an agent (e.g. a robot) trained using deep reinforcement learning. This memory is composed of large temporal vectors updated when the agent moves in an environment and is not trivial to understand. It is often referred to as a black box as only inputs (images) and outputs (actions) are intelligible for humans. Using DRLViz, experts are assisted to interpret using memory reduction interactions, to investigate parts of the memory role when errors have been made, and ultimately to improve the agent training process. We report on several examples of use of DRLViz, in the context of video games simulators (ViZDoom) for a navigation scenario with item gathering tasks. We also report on experts evaluation using DRLViz, and applicability of DRLViz to other scenarios and navigation problems beyond simulation games, as well as its contribution to black box models interpret-ability and explain-ability in the field of visual analytics.


